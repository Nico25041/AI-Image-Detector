{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1D+cZpx3mL6Mkrmfgp1KW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nico25041/AI-Image-Detector/blob/main/AI_finder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download Dataset\n",
        "path = kagglehub.dataset_download(\"birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "1cTNgllwHnbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load train and test datasets\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load entire training set\n",
        "full_train_dataset = datasets.ImageFolder(\"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train\", transform=transform)\n",
        "\n",
        "#Split given training set into 90% training set, 10% validation set\n",
        "train_size = int(0.9 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "#Create test data set\n",
        "test_dataset = datasets.ImageFolder(root='/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test', transform=transform)\n",
        "\n",
        "#Set up data loaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size= 64, shuffle=True, num_workers=8)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False,num_workers=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False,num_workers=8)\n"
      ],
      "metadata": {
        "id": "c3r-ChdV_6hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Initialize CNN block\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(-1, 128 * 16 * 16)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CQ-qMVFm3rZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#Save function\n",
        "#saves the state in folder expressing which epoch it was from\n",
        "def save_checkpoint(model, epoch):\n",
        "    model_folder = \"model/checkpoint/\"\n",
        "\n",
        "    model_out_path = model_folder + \"model_{}.pth\".format(epoch)\n",
        "    state = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict()\n",
        "    }\n",
        "    if not os.path.exists(model_folder):\n",
        "        os.makedirs(model_folder)\n",
        "    torch.save(state, model_out_path)\n",
        "    sav = \"Checkpoint saved to {}\".format(model_out_path)"
      ],
      "metadata": {
        "id": "A3w7LYlQYIO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Two different models can be trained through this cell\n",
        "# 1)Resnet50 pretrained where hyper parameters are just trained to this dataset\n",
        "# 2)Custom CNN\n",
        "\n",
        "from types import CellType\n",
        "from torchvision import datasets, transforms, models\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Custom Model\n",
        "model = CNN().to(device)\n",
        "\n",
        "#Resnet Model\n",
        "\n",
        "#model = models.resnet50(pretrained=True)\n",
        "#num_features = model.fc.in_features\n",
        "#model.fc = nn.Linear(num_features, 3)\n",
        "#model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labels in train_dataloader:\n",
        "        imgs, labels = imgs.to(device), torch.tensor(labels).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        ce_loss = F.cross_entropy(outputs, labels)\n",
        "        ce_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += ce_loss.item()\n",
        "\n",
        "#Validation Accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
        "    save_checkpoint(model, epoch)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "id": "llUiMXs13utT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy Testing\n",
        "myModel = torch.load(\"model/checkpoint/model_14.pth\")\n",
        "model.load_state_dict(myModel[\"model_state_dict\"])\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_dataloader:\n",
        "        imgs, labels = imgs.to(device), torch.tensor(labels).to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "62fQ2hx-4ZGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing for the confusion matrix, where all predictions and labels are put into lists for the graph\n",
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_dataloader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "R5HQ7zoIcn5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Real\", \"AI\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4vC8aAgidGGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}